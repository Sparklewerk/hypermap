{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1t8QUTB7qP3"
      },
      "source": [
        "# Hypermapping Bastard Gan Punks\n",
        "\n",
        "<center>\n",
        "<img src=\"https://sparklewerk.com/projects/hypermaps/bastards_plot_2.png?uncache_please\" alt=\"demo hypermap\" />\n",
        "</center>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://sparklewerk.com/images/brands/sparklewerk/sparklewerk_wordmark.png\" alt=\"Sparklewerk wordmark\" align=\"center\" />\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzwKUbeS75c8"
      },
      "source": [
        "## GPU detection\n",
        "\n",
        "UMAP knows how to use server side GPUs and Colab lets one use one for free.\n",
        "\n",
        "In the menubar, select `Runtime→Change Runtime Type`, then\n",
        "select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "\n",
        "First, let's see if we have an Nvidia GPU.\n",
        "\n",
        "In the following code cell, if the result is:\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver.\n",
        "```\n",
        "Then that means the Runtime is not set to GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC107Gdjm7Aa"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all GPUs on Colab are Nvidia models. So, the above may not have found an Nvidia GPU yet there may still be another manufacturers GPU. Here is how to check:"
      ],
      "metadata": {
        "id": "Yvgv_y1mZRSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "QI77E1CsXsSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "WGlBtIW_Wrgc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uULFoZy9m7AV"
      },
      "source": [
        "### Constants\n",
        "\n",
        "These two constants control how big the bastards we be resized to:\n",
        "- `bastards_into_umap_size`: (int, int) for UMAP processing\n",
        "- `bastards_into_projector_size`: (int, int) for Projector viz spritesheet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE2jpTewng9d"
      },
      "outputs": [],
      "source": [
        "# But first some switches:\n",
        "render_2d_umap_plot_image = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXBiyIJFhNuX"
      },
      "source": [
        "#### UMAP input size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM-7G7RJgyZ8"
      },
      "outputs": [],
      "source": [
        "bastards_into_umap_width = bastards_into_umap_height = 48\n",
        "bastards_into_umap_size = (bastards_into_umap_width, bastards_into_umap_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saXhIKBpgynY"
      },
      "source": [
        "#### Projector sprite size\n",
        "By experimentation, it seems that for `bastards_into_projector_size`, (96, 96) is a decent downsampling size:\n",
        "\n",
        "- (24, 24) is too small to see much detail. It does work but meh…\n",
        "- (48, 48) kinda works but meh\n",
        "- (64, 64) is a round size\n",
        "- (96, 96) is too big for Projector\n",
        "\n",
        "Although (96, 96) is a nice size (details show well), Projector refuses to accept a spritesheet that large. Largest it will accept is (8192, 8192) and (9600, 9600) for 10K would be too big.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0itwuz3Hmn1"
      },
      "outputs": [],
      "source": [
        "bastards_into_projector_witdth = bastards_into_projector_height = 64\n",
        "bastards_into_projector_size = (bastards_into_projector_witdth, bastards_into_projector_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwuRaZsOHoG7"
      },
      "source": [
        "### Installs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-jq5nxOm7AX"
      },
      "outputs": [],
      "source": [
        "# TODO: there are ways to detect if umap-learn has already been installed. \n",
        "# Would make this a wee faster on repeat runs.\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQR010U82wo"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG7k7L5jm7AZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import umap\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from math import trunc\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import asarray\n",
        "from packaging import version\n",
        "from skimage.color import rgb2gray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZlCPTeto3aT"
      },
      "outputs": [],
      "source": [
        "# TODO: is this needed these days?\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQGjhOu7dEe"
      },
      "source": [
        "### TensorFlow set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44cQlcA97Eow"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # This tensorflow_version is a Colab-only thing\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
        "\n",
        "from tensorboard.plugins import projector\n",
        "%load_ext tensorboard\n",
        "\n",
        "# TODO: print tensorboard version?\n",
        "\n",
        "tensorboard_data_dump_dir = '/content/tensorboard_data'\n",
        "if not os.path.exists(tensorboard_data_dump_dir):\n",
        "  os.makedirs(tensorboard_data_dump_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmbC3fPZ9BbR"
      },
      "source": [
        "## Data wrangling\n",
        "\n",
        "The full bastards image collection can be found in the allbastards.com repo on GitHub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1QDRfndm7Ab"
      },
      "source": [
        "### Inspect data\n",
        "\n",
        "First let's make sure we're parsing the data correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAhRiNOTm7Ab"
      },
      "outputs": [],
      "source": [
        "# If repo has already been cloned, doing so again will error so let's not\n",
        "if not os.path.isdir('allbastards.com'):\n",
        "  !git clone https://github.com/rkalis/allbastards.com.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRCb9GOsm7Ac"
      },
      "outputs": [],
      "source": [
        "!ls allbastards.com/public/img/full | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTvLHAlfm7Ad"
      },
      "outputs": [],
      "source": [
        "path, dirs, files = next(os.walk(\"allbastards.com/public/img/full\"))\n",
        "file_count = len(files)\n",
        "print(file_count)\n",
        "print(f'files[0] = \"{files[0]}\"')\n",
        "print(f'Trimmed  = \"{files[0][:-5]}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMiv1vwJwoff"
      },
      "outputs": [],
      "source": [
        "def get_bastard_by_id(an_id: int):\n",
        "  a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",f'{an_id}.webp'))\n",
        "  return a_bastard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv-JYPPPm7Ad"
      },
      "source": [
        "The calmAF bastards (read: static webp files) are all (1024,1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DY3Jwnom7Ae"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "calm_ids = []\n",
        "hyped_ids = []\n",
        "\n",
        "for file in files:\n",
        "    a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",file))\n",
        "    if a_bastard.is_animated:\n",
        "      hyped_ids.append(int(file[:-5]))\n",
        "    else:\n",
        "      calm_ids.append(int(file[:-5]))\n",
        "                \n",
        "print(f'calms: {len(calm_ids)}')\n",
        "print(f'hypes: {len(hyped_ids)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSp0huOHm7Af"
      },
      "source": [
        "Let's use Punk #42 as our poster child. And isn't he just a handsome boy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W3IoKsKm7Af"
      },
      "outputs": [],
      "source": [
        "a_bastard_filename = os.path.join('allbastards.com/public/img/full', '42.webp')\n",
        "a_bastard = Image.open(a_bastard_filename) \n",
        "\n",
        "width, height = a_bastard.size\n",
        "print('size = (', width, ',', height, ')')\n",
        "print('format = ', a_bastard.format)\n",
        "print('mode = ', a_bastard.mode)\n",
        "\n",
        "plt.imshow(np.asarray(a_bastard))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCYiPFuNm7Ag"
      },
      "source": [
        "Images of size (1024,1024) is 2 to the 10th. Mega. We need to downsample that before presenting the data to UMAP. And the bastards are color images (R,G,B) but UMAP wants simple scalors for values, so the color needs to be grayscaled. (Notice how the axis numbering changes.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBWUl8Z3m7Ag"
      },
      "outputs": [],
      "source": [
        "print(f'Downsampling to {bastards_into_umap_size}')\n",
        "a_bastard_downsized = a_bastard.resize(bastards_into_umap_size)\n",
        "a_bastard_downsized_grayed = rgb2gray(np.asarray(a_bastard_downsized))\n",
        "\n",
        "plt.imshow(a_bastard_downsized_grayed, interpolation='nearest', cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A91bVF6Km7Ah"
      },
      "source": [
        "And then we flatten() the images to make them a sub-array of the 2D array to be presented to UMAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNaon8I1m7Ah"
      },
      "outputs": [],
      "source": [
        "print(a_bastard_downsized_grayed.flatten()[0])\n",
        "print(a_bastard_downsized_grayed.flatten()[254])\n",
        "print(type(a_bastard_downsized_grayed.flatten()[254]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWQgmGWRErug"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BueqR3um7Ai"
      },
      "source": [
        "Yup, that's the correct data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9mWeZ0K_R4g"
      },
      "source": [
        "## UMAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPV2WKyeEhzS"
      },
      "source": [
        "### Data transforming\n",
        "\n",
        "Next we manipulate the data in prep for feeding it to UMAP.\n",
        "\n",
        "We need to present all the bastards to Projector in the structure it wants, which is a 2D array. That array is a list of all the bastards to be projected. Each bastard has to be recast as a 1D feature vector, each feature a single number. So, each 2D image gets reshaped to a 1D array, and each color pixel (R,G,B) gets grayscaled to a single value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOym0k1km7Ai"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def load_calm_bastards_from_repo():\n",
        "  # TODO: Surely there is some elegant pythonic way of doing this.\n",
        "\n",
        "  # Just create the column names first, one for each pixel\n",
        "  number_of_pixels = bastards_into_umap_width * bastards_into_umap_height\n",
        "  feat_cols = [ 'pixel'+str(i) for i in range(number_of_pixels) ]\n",
        "\n",
        "  calms_images = np.zeros((len(calm_ids), number_of_pixels))\n",
        "  print(f'Shape of calm images: {calms_images.shape}')\n",
        "\n",
        "  idx = 0\n",
        "  for file in files:\n",
        "    a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",file))\n",
        "    # TODO: let's get a progress bar going here. We do know how many files to process.\n",
        "    if not a_bastard.is_animated:\n",
        "      a_smaller_bastard = a_bastard.resize(bastards_into_umap_size)\n",
        "      a_bastard_grayed = rgb2gray(asarray(a_smaller_bastard)) # This normalizes to [0..1]\n",
        "      calms_images[idx] = a_bastard_grayed.flatten()\n",
        "      idx = idx + 1\n",
        "        \n",
        "  return pd.DataFrame(calms_images,columns=feat_cols)\n",
        "\n",
        "calms = load_calm_bastards_from_repo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXOLff-3m7Aj"
      },
      "outputs": [],
      "source": [
        "# Optionally, peek inside the DataFrame\n",
        "calms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d220hKB-qh1"
      },
      "source": [
        "### Visualize embedding\n",
        "\n",
        "Note: we are not setting a random seed (See docs for [random_state](https://umap-learn.readthedocs.io/en/latest/reproducibility.html)). This way is faster. The plots will look different between runs though. But we are not aiming for reproducable science papers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsGTEM0fm7Aj"
      },
      "outputs": [],
      "source": [
        "def embed_data():\n",
        "  return umap.UMAP(n_neighbors=10, min_dist=0.1, n_components=2).fit_transform(calms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyu2eiVdm7Aj"
      },
      "outputs": [],
      "source": [
        "def show_simple_scatterplot(): \n",
        "  \"\"\"\n",
        "  Plots all bastards in 2D space as blue dots, no images\n",
        "  \"\"\"\n",
        "  subset_of_embedding = embedding #[0:100]\n",
        "  fig = plt.figure(figsize=(15, 15))\n",
        "  plt.scatter(subset_of_embedding[:,0], subset_of_embedding[:,1], s=1)\n",
        "  plt.show()\n",
        "\n",
        "if render_2d_umap_plot_image:\n",
        "  show_simple_scatterplot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRjBT563m7Ak"
      },
      "source": [
        "So, what is the range of the X and Y values? Those are the bounding box of the plot.\n",
        "\n",
        "[TODO: this should just be in the code. No manual calc'ing.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OuerVlBm7Ak"
      },
      "outputs": [],
      "source": [
        "if render_2d_umap_plot_image:\n",
        "  embedding = embed_data()\n",
        "\n",
        "  print(type(embedding))\n",
        "  print('({}, {})'.format(np.min(embedding[:,0]), np.max(embedding[:,0])))\n",
        "  print('({}, {})'.format(np.min(embedding[:,1]), np.max(embedding[:,1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qmbssawm7Ak"
      },
      "source": [
        "So, if we added 2 to each dimension that would get everything possitive.\n",
        "\n",
        "then the range is ~0--<15, and ~0--<11.\n",
        "\n",
        "If that were to be blown up to (1000,1000) should multiple about 1000/15 ~= 67. So, 66 is safe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEoSrd_Vm7Ak"
      },
      "source": [
        "#### 2D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD1huZyKm7Ak"
      },
      "outputs": [],
      "source": [
        "def scatter_bastards_in_2d():\n",
        "  canvas_dimensions = (2000, 2000)\n",
        "  embedding_neighborhood = Image.new('RGBA', canvas_dimensions, (0,0,0,0))\n",
        "  print(f'For rendering in TensorBoard Projector, down sampling to {bastards_into_projector_size}')\n",
        "\n",
        "  idx = 0\n",
        "  for file in files:\n",
        "    a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",file))\n",
        "    if not a_bastard.is_animated:\n",
        "      a_smaller_bastard = a_bastard.resize(bastards_into_projector_size)\n",
        "      location = ( trunc((embedding[idx,0]+2)*132) , trunc((embedding[idx,1]+2)*132) )\n",
        "      embedding_neighborhood.paste(a_smaller_bastard, location) #, mask=a_smaller_bastard)\n",
        "      idx = idx + 1\n",
        "  return embedding_neighborhood    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jxZYyIznTpZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if render_2d_umap_plot_image:\n",
        "  scattered_bastards = scatter_bastards_in_2d()\n",
        "  display(scattered_bastards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcf1UsAR21F-"
      },
      "source": [
        "#### 3D\n",
        "\n",
        "Next, feed the data into TensorBoard's Embedding Projector (or simply, Projector). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXYhzjK04BIu"
      },
      "source": [
        "##### Sprite sheet\n",
        "\n",
        "To actually show the images floating in a 2D or 3D space, TensorBoard Projector requires a sprite sheet which contains a sprite for each image to be projected.\n",
        "\n",
        "For now we're just using the calmAFs (static images), not the hypedAFs (animated GIFs). There are 10459 calms and 847 hypeds. The sprite sheet needs to be square, so let's just use the first 10000, for 100 x 100 sprite sheet. [TODO: plot all 10459 calms.]\n",
        "\n",
        "The sprite sheet can be a PNG or a JPEG. (Not sure if an animated GIF will work in Projector.) So, for just-the-calms we'll go PNG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Xe5Izz37qO"
      },
      "outputs": [],
      "source": [
        "def create_sprite_sheet():\n",
        "  spritesheet_square_length = 100 # 10,000 = 100 x 100 in spritesheet\n",
        "  master_width = bastards_into_projector_witdth * spritesheet_square_length\n",
        "  master_height = bastards_into_projector_witdth * spritesheet_square_length\n",
        "  spriteimage = Image.new(\n",
        "    mode='RGBA',\n",
        "    size=(master_width, master_height),\n",
        "    color=(0,0,0,0) # fully transparent\n",
        "  )\n",
        "\n",
        "  # This CUT_OFF_LIMIT is a vile hack. Spritesheet must be square. Padding needed, but not now\n",
        "  CUT_OFF_LIMIT = 10000 # TODO: remove this hack, sprite up ENTIRE collection\n",
        "\n",
        "  punk_index = 0\n",
        "  for x in range(CUT_OFF_LIMIT):\n",
        "    a_punk = get_bastard_by_id(calm_ids[x]).resize(bastards_into_projector_size)\n",
        "    div, mod = divmod(punk_index, spritesheet_square_length)\n",
        "    h_loc = bastards_into_projector_witdth * div\n",
        "    w_loc = bastards_into_projector_witdth * mod\n",
        "    spriteimage.paste(a_punk, (w_loc, h_loc))\n",
        "    punk_index = punk_index + 1\n",
        "\n",
        "  return spriteimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP6DK-lK6BS6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "def write_files_for_tensorboard():\n",
        "  # First, generate spritesheet for Projector to use downsammpled sprites\n",
        "  sprite_sheet = create_sprite_sheet()\n",
        "  sprite_filename = os.path.join(tensorboard_data_dump_dir, 'embeddings/sprite.png')\n",
        "  if not os.path.exists(os.path.dirname(sprite_filename)):\n",
        "    os.makedirs(os.path.dirname(sprite_filename))\n",
        "  sprite_sheet.save(sprite_filename)\n",
        "\n",
        "  # Next the data for the dimensionality reducers (UMAP, t-SNE, PCA) to crunch on\n",
        "  vectorized_punks = tf.Variable(calms[0:9999])\n",
        "  checkpoint = tf.train.Checkpoint(embedding=vectorized_punks)\n",
        "  checkpoint.save(os.path.join(tensorboard_data_dump_dir, 'embedding.ckpt'))\n",
        "\n",
        "\n",
        "  config = projector.ProjectorConfig()\n",
        "  embedder = config.embeddings.add()\n",
        "\n",
        "  embedder.tensor_name = 'embedding/.ATTRIBUTES/VARIABLE_VALUE'\n",
        "\n",
        "  embedder.sprite.image_path = sprite_filename\n",
        "  embedder.sprite.single_image_dim.extend(bastards_into_projector_size)\n",
        "\n",
        "  projector.visualize_embeddings(tensorboard_data_dump_dir, config)\n",
        "\n",
        "write_files_for_tensorboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bug in TensorBoard launch**\n",
        "\n",
        "**NOTE:** TensorBoard regularly fails to find the data just written to the file system. If so just rerun the following cell; that usually gets it to wake up and get to work.\n",
        "\n",
        "Also note that:\n",
        "- \"Fetching tensor values…\" normally takes a minute or two\n",
        "- \"Fetching sprite image…\" normally takes a minute\n",
        "- Then PCA will run automatically\n",
        "- When PCA is done, click on UMAP or tSNE for other hypermap algorithms that will each provide a different view of the collection."
      ],
      "metadata": {
        "id": "wGVhvRrSFp2s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqtKUjsm2eSu"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir={tensorboard_data_dump_dir}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YzwKUbeS75c8"
      ],
      "name": "hypermapping_bganpunks.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}