{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1t8QUTB7qP3"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://sparklewerk.com/collections/bganpunks/bganpunks_poster_2_by_1.png\" alt=\"demo hypermap\" />\n",
        "</center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKQJnrVyhmDl"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This is a Jupyter notebook. You can run this MIT licensed open source code for free on Google's Colab.\n",
        "\n",
        "This notebook hypermaps [the BASTARD GAN PUNKS V2 NFT collection](https://bastardganpunks.club/). For more information on hypermaps, please visit [sparklewerk.com](https://sparklewerk.com/projects/hypermaps).\n",
        "\n",
        "This is free code running on free compute. If you are dissatisfied, we will have customer service get you a full refund. If on the other hand, you have constructive feedback please join the conversation on GitHub: [hypermap issues](https://github.com/ManyHands/hypermap/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpA8XJwViMAP"
      },
      "source": [
        "## License\n",
        "\n",
        "Copyright (c) 2022, Many Hands SPC. All Rights Reserved.\n",
        "\n",
        "Licensed under the MIT License (the \"License\").\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oo4mlJVsh8CS"
      },
      "outputs": [],
      "source": [
        "# Licensed under the MIT License (the \"License\");\n",
        "#\n",
        "# MIT License\n",
        "#\n",
        "# Copyright (c) 2022, Many Hands SPC\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in all\n",
        "# copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGlBtIW_Wrgc"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uULFoZy9m7AV"
      },
      "source": [
        "### Constants\n",
        "\n",
        "All the configuration constants are defined first. Constants are control switches for configuring this machine before it runs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J1myQjBhnC3"
      },
      "source": [
        "#### 2D plots\n",
        "\n",
        "Computing the 2D renderings takes a few minutes. If you are only interested in the 3D, there is a switch to disable all the 2D compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CE2jpTewng9d"
      },
      "outputs": [],
      "source": [
        "# To save time the entire 2D rendering part of this can be disabled:\n",
        "render_2d_plots = False\n",
        "\n",
        "# How big to make the final Image the NFTs will be plotted into\n",
        "# Twitter allows as big as (4096, 4096)\n",
        "canvas_dimensions = (4096, 4096) # Maximum allowed on Twitter images \n",
        "                  # (4096, 2304) # 16:9 is for Twitter card large images\n",
        "                  # (4096, 2048) # 2:1\n",
        "\n",
        "# Similar to CSS padding:\n",
        "canvas_padding_percentage = 0.075\n",
        "\n",
        "# How big to plot the bastards on that canvas:\n",
        "bastards_into_canvas_width = bastards_into_canvas_height = 96\n",
        "bastards_into_canvas_size = (bastards_into_canvas_width, bastards_into_canvas_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXBiyIJFhNuX"
      },
      "source": [
        "#### UMAP input size\n",
        "\n",
        "There are two constants that control how small the bastards will be resized to for processing. They start naturally as squares of (1024, 1024) end as squares of (X, X):\n",
        "- `bastards_into_umap_width`: (int, int) for UMAP processing\n",
        "- `bastards_into_projector_width`: (int, int) for Projector viz spritesheet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nM-7G7RJgyZ8"
      },
      "outputs": [],
      "source": [
        "bastards_into_umap_width = bastards_into_umap_height = 24\n",
        "bastards_into_umap_size = (bastards_into_umap_width, bastards_into_umap_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saXhIKBpgynY"
      },
      "source": [
        "#### Projector sprite size\n",
        "By experimentation, it seems that for `bastards_into_projector_size`, (96, 96) is a decent downsampling size:\n",
        "\n",
        "- (24, 24) is too small to see much detail. It does work but meh…\n",
        "- (48, 48) kinda works but meh\n",
        "- (64, 64) is a round size (1024px/16 = 64px)\n",
        "- (96, 96) is too big for Projector spritesheet\n",
        "\n",
        "Although (96, 96) is a nice size (details show well), Projector refuses to accept a spritesheet that large. Largest it will accept is (8192, 8192) and (9600, 9600) for 10K would be too big. [TODO: could subset punks before UMAPing]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W0itwuz3Hmn1"
      },
      "outputs": [],
      "source": [
        "bastards_into_projector_witdth = bastards_into_projector_height = 24\n",
        "bastards_into_projector_size = (bastards_into_projector_witdth, bastards_into_projector_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwuRaZsOHoG7"
      },
      "source": [
        "### Installs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-jq5nxOm7AX",
        "outputId": "89ff5d5b-e143-48d3-989a-77a6e9b4f0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 27.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.0.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82708 sha256=eb04ef8e5cbf58cf5d87967ba10692d5f4a9da2d1169fb315f221eefb5d00d55\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=9a615ea59920163c523d58c476f130a64d1fee86e5dd45a104a8b3fcbce1e4d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.6 umap-learn-0.5.2\n"
          ]
        }
      ],
      "source": [
        "# TODO: there are ways to detect if umap-learn has already been installed. \n",
        "# Would make this a wee faster on repeat runs.\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQR010U82wo"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fG7k7L5jm7AZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import umap\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image, ImageDraw\n",
        "from ipywidgets import IntProgress\n",
        "from math import trunc\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import asarray\n",
        "from packaging import version\n",
        "from skimage.color import rgb2gray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQGjhOu7dEe"
      },
      "source": [
        "### TensorFlow set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzwKUbeS75c8"
      },
      "source": [
        "## GPU detection\n",
        "\n",
        "At least one of the hypermapping algorithms, [UMAP](https://umap-learn.readthedocs.io/en/latest/), knows how to use server side GPUs and Colab provides such toys for free use.\n",
        "\n",
        "In the menubar, select `Runtime→Change Runtime Type`, then\n",
        "select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "\n",
        "First, let's see if we have an Nvidia GPU.\n",
        "\n",
        "In the following code cell, if the result is:\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver.\n",
        "```\n",
        "Then that means the Runtime is not set to GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC107Gdjm7Aa",
        "outputId": "047b750a-56b3-4764-edec-52be58a2c9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  3 11:24:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44cQlcA97Eow",
        "outputId": "69e68236-beb3-45d0-fd4a-3d0f65048a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version:  2.7.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # This tensorflow_version is a Colab-only thing\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
        "\n",
        "from tensorboard.plugins import projector\n",
        "%load_ext tensorboard\n",
        "\n",
        "# TODO: print tensorboard version?\n",
        "\n",
        "tensorboard_data_dump_dir = '/content/tensorboard_data'\n",
        "if not os.path.exists(tensorboard_data_dump_dir):\n",
        "  os.makedirs(tensorboard_data_dump_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvgv_y1mZRSV"
      },
      "source": [
        "Not all GPUs on Colab are Nvidia models. So, the above may not have found an Nvidia GPU yet there may still be another manufacturers GPU. Here is how to check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI77E1CsXsSj",
        "outputId": "e9d57852-ea2e-46b8-c928-526c2fd6b551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyKWLf9GZEjS"
      },
      "source": [
        "Hey, if you really want to continue without a GPU, you _could_ but it will be slow. Just comment out the above `raise SystemError()` and rerun all. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmbC3fPZ9BbR"
      },
      "source": [
        "## Data wrangling\n",
        "\n",
        "The full bastards image collection can be found in the allbastards.com repo on GitHub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1QDRfndm7Ab"
      },
      "source": [
        "### Inspect data\n",
        "\n",
        "First let's make sure we're parsing the data correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAhRiNOTm7Ab",
        "outputId": "aa20bdf2-68ec-44a7-cf67-27633b2e9a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'allbastards.com'...\n",
            "remote: Enumerating objects: 86718, done.\u001b[K\n",
            "remote: Counting objects: 100% (68380/68380), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11489/11489), done.\u001b[K\n",
            "remote: Total 86718 (delta 57667), reused 67365 (delta 56887), pack-reused 18338\u001b[K\n",
            "Receiving objects: 100% (86718/86718), 195.29 MiB | 17.29 MiB/s, done.\n",
            "Resolving deltas: 100% (60838/60838), done.\n",
            "Checking out files: 100% (22680/22680), done.\n"
          ]
        }
      ],
      "source": [
        "# If repo has already been cloned, doing so again will error so let's not\n",
        "if not os.path.isdir('allbastards.com'):\n",
        "  !git clone https://github.com/rkalis/allbastards.com.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRCb9GOsm7Ac",
        "outputId": "3623136a-2dff-45a0-a45c-b7dc611892ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11306\n"
          ]
        }
      ],
      "source": [
        "!ls allbastards.com/public/img/full | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTvLHAlfm7Ad",
        "outputId": "77f17ccf-7760-43b0-e184-c033db4bca9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11306\n",
            "files[0] = \"4333.webp\"\n",
            "Trimmed  = \"4333\"\n"
          ]
        }
      ],
      "source": [
        "path, dirs, files = next(os.walk(\"allbastards.com/public/img/full\"))\n",
        "file_count = len(files)\n",
        "print(file_count)\n",
        "print(f'files[0] = \"{files[0]}\"')\n",
        "print(f'Trimmed  = \"{files[0][:-5]}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dMiv1vwJwoff"
      },
      "outputs": [],
      "source": [
        "def get_bastard_by_id(an_id: int):\n",
        "  a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",f'{an_id}.webp'))\n",
        "  return a_bastard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv-JYPPPm7Ad"
      },
      "source": [
        "The calmAF bastards (read: static webp files) are all (1024,1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DY3Jwnom7Ae"
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "# this can take about 15 seconds\n",
        "\n",
        "calm_ids = []\n",
        "hyped_ids = []\n",
        "\n",
        "# TODO: Need datastructure that has IDs and such not just image. PyTink? Derp: https://github.com/ManyHands/hypermap/issues/25\n",
        "for file in files:\n",
        "    a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",file))\n",
        "    if a_bastard.is_animated:\n",
        "      hyped_ids.append(int(file[:-5]))\n",
        "    else:\n",
        "      calm_ids.append(int(file[:-5]))\n",
        "                \n",
        "print(f'calms: {len(calm_ids)}')\n",
        "print(f'hypes: {len(hyped_ids)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSp0huOHm7Af"
      },
      "source": [
        "Let's use Punk #42 as our poster child. Nice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W3IoKsKm7Af"
      },
      "outputs": [],
      "source": [
        "a_bastard_filename = os.path.join('allbastards.com/public/img/full', '42.webp')\n",
        "a_bastard = Image.open(a_bastard_filename) \n",
        "\n",
        "width, height = a_bastard.size\n",
        "print('size = (', width, ',', height, ')')\n",
        "print('format = ', a_bastard.format)\n",
        "print('mode = ', a_bastard.mode)\n",
        "\n",
        "plt.imshow(np.asarray(a_bastard))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCYiPFuNm7Ag"
      },
      "source": [
        "Images of size (1024,1024) is 2 to the 10th. Mega. We need to downsample that before presenting the data to UMAP. And the bastards are color images (R,G,B) but UMAP wants simple scalors for values, so the color needs to be grayscaled. (Notice how the axis numbering changes.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBWUl8Z3m7Ag"
      },
      "outputs": [],
      "source": [
        "print(f'Downsampling to {bastards_into_umap_size}')\n",
        "a_bastard_downsized = a_bastard.resize(bastards_into_umap_size)\n",
        "a_bastard_downsized_grayed = rgb2gray(np.asarray(a_bastard_downsized))\n",
        "\n",
        "plt.imshow(a_bastard_downsized_grayed, interpolation='nearest', cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A91bVF6Km7Ah"
      },
      "source": [
        "And then we flatten() the images to make them a sub-array of the 2D array to be presented to UMAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNaon8I1m7Ah"
      },
      "outputs": [],
      "source": [
        "print(a_bastard_downsized_grayed.flatten()[0])\n",
        "print(a_bastard_downsized_grayed.flatten()[254])\n",
        "print(type(a_bastard_downsized_grayed.flatten()[254]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BueqR3um7Ai"
      },
      "source": [
        "Yup, that's the correct data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9mWeZ0K_R4g"
      },
      "source": [
        "## UMAP\n",
        "\n",
        "First we need to do the learning part, then once we have a trained model we embed and visualize the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPV2WKyeEhzS"
      },
      "source": [
        "### Vectorize data\n",
        "\n",
        "Next we manipulate the data in prep for feeding it to UMAP.\n",
        "\n",
        "We need to present all the bastards to Projector in the structure it wants, which is a 2D array. That array is a list of all the bastards to be projected. Each bastard has to be recast as a 1D feature vector, each feature a single number. So, each 2D image gets reshaped to a 1D array, and each color pixel (R,G,B) gets grayscaled to a single value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOym0k1km7Ai"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# This seems to take on Colab: ~2.5m\n",
        "\n",
        "def load_calm_bastards_from_repo():\n",
        "  # TODO: Surely there is some elegant pythonic way of doing this.\n",
        "\n",
        "  # Just create the column names first, one for each pixel\n",
        "  number_of_pixels = bastards_into_umap_width * bastards_into_umap_height\n",
        "  feat_cols = [ 'pixel'+str(i) for i in range(number_of_pixels) ]\n",
        "\n",
        "  calms_images = np.zeros((len(calm_ids), number_of_pixels))\n",
        "  print(f'Shape of calm images: {calms_images.shape}')\n",
        "\n",
        "  idx = 0\n",
        "  for file in files:\n",
        "    a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",file))\n",
        "    # TODO: let's get a progress bar going here. We do know how many files to process.\n",
        "    if not a_bastard.is_animated:\n",
        "      a_smaller_bastard = a_bastard.resize(bastards_into_umap_size)\n",
        "      a_bastard_grayed = rgb2gray(asarray(a_smaller_bastard)) # This normalizes to [0..1]\n",
        "      calms_images[idx] = a_bastard_grayed.flatten()\n",
        "      idx = idx + 1\n",
        "        \n",
        "  return pd.DataFrame(calms_images,columns=feat_cols)\n",
        "\n",
        "calms = load_calm_bastards_from_repo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXOLff-3m7Aj"
      },
      "outputs": [],
      "source": [
        "# Optionally, peek inside the DataFrame\n",
        "calms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d220hKB-qh1"
      },
      "source": [
        "### Visualize embedding\n",
        "\n",
        "All the above was data wrangling; now it's time to crunch some numbers.\n",
        "\n",
        "Note: we are not setting a random seed (See docs for [random_state](https://umap-learn.readthedocs.io/en/latest/reproducibility.html)). This way is faster. The plots will look different between runs though. But we are not aiming for reproducable science papers.\n",
        "\n",
        "This next one-liner function is where the UMAP happens, for the server-side number crunch; TensorBoard Projecter does its own UMAP client-side in the browser's GPU. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsGTEM0fm7Aj"
      },
      "outputs": [],
      "source": [
        "def embed_data():\n",
        "  return umap.UMAP(n_neighbors=20, min_dist=0.1, n_components=2).fit_transform(calms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEoSrd_Vm7Ak"
      },
      "source": [
        "#### 2D hypermap the calmAFs\n",
        "\n",
        "First let us plot so 2D static images before getting into 3D and/or interactive implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyu2eiVdm7Aj"
      },
      "outputs": [],
      "source": [
        "def show_simple_scatterplot(): \n",
        "  \"\"\"\n",
        "  Plots all bastards in 2D space as blue dots, no images\n",
        "  \"\"\"\n",
        "  subset_of_embedding = embedding #[0:100] TODO: if want subsetting, need IDs for Projector\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "  plt.scatter(subset_of_embedding[:,0], subset_of_embedding[:,1], s=1)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRjBT563m7Ak"
      },
      "source": [
        "The min to max ranges of the X and Y values are the bounding box of the plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OuerVlBm7Ak"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "if render_2d_plots:\n",
        "  embedding = embed_data()\n",
        "\n",
        "  print('({}, {})'.format(np.min(embedding[:,0]), np.max(embedding[:,0])))\n",
        "  print('({}, {})'.format(np.min(embedding[:,1]), np.max(embedding[:,1])))\n",
        "  \n",
        "  show_simple_scatterplot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD1huZyKm7Ak"
      },
      "outputs": [],
      "source": [
        "def generate_canvas():\n",
        "  \"\"\"\n",
        "  Plot a vertical gradient between two colors. Do it first and it\n",
        "  is an analogy to a CSS gradient background.\n",
        "  Via https://stackoverflow.com/a/63138452\n",
        "  \"\"\"\n",
        "  # color_top = '#66023c'\n",
        "  # color_bottom = '#0a0006'\n",
        "  color_top = color_bottom = '#ff00a2'\n",
        "\n",
        "  canvas = Image.new('RGB', canvas_dimensions, color_top)\n",
        "  #base = Image.new('RGB', (width, height), colour1)\n",
        "  top_coat = Image.new('RGB', canvas_dimensions, color_bottom)\n",
        "  mask = Image.new('L', canvas_dimensions)\n",
        "  mask_data = []\n",
        "  for y in range(canvas_dimensions[1]):\n",
        "    mask_data.extend([int(255 * (y / canvas_dimensions[1]))] * canvas_dimensions[0])\n",
        "\n",
        "  # print(f'mask.size: {mask.size} a.k.a {mask.size[0] * mask.size[1]}, len(mask_data): {len(mask_data)}')\n",
        "\n",
        "  mask.putdata(mask_data)\n",
        "  canvas.paste(top_coat, (0, 0), mask)\n",
        "  return canvas\n",
        "\n",
        "def scatter_bastards_in_2d(invert_vertically :bool = False):\n",
        "  #cv2_anvas_dimensions = ((1024+512), (1024+512))\n",
        "  canvas_width = canvas_dimensions[0]\n",
        "  canvas_height = canvas_dimensions[1]\n",
        "\n",
        "  x_min = np.min(embedding[:,0])\n",
        "  x_max = np.max(embedding[:,0])\n",
        "  x_delta = x_max - x_min\n",
        "  x_factor = canvas_width / x_delta\n",
        "\n",
        "  y_min = np.min(embedding[:,1]) \n",
        "  y_max = np.max(embedding[:,1])\n",
        "  y_delta = y_max - y_min\n",
        "  y_factor = canvas_height / y_delta\n",
        "\n",
        "  print(f'X: ({x_min}, {x_max})')\n",
        "  print(f'Y: ({y_min}, {y_max})')\n",
        "\n",
        "  canvas = generate_canvas()\n",
        "\n",
        "  def translate_to_canvas(x, y):\n",
        "    pad_percentage = canvas_padding_percentage\n",
        "    x_dest = trunc((x - x_min) * x_factor * (1 - (2*pad_percentage))) + trunc((pad_percentage * canvas_width))\n",
        "\n",
        "    if invert_vertically:\n",
        "      y_dest = canvas_height - ( trunc((y - y_min) * y_factor * (1 - (2*pad_percentage))) + trunc((pad_percentage * canvas_height)) )\n",
        "    else:\n",
        "      y_dest = trunc((y - y_min) * y_factor * (1 - (2*pad_percentage))) + trunc((pad_percentage * canvas_height))\n",
        "\n",
        "    # Need to center image on the (X,Y), not upper left on the (X,Y)\n",
        "    x_dest -= bastards_into_canvas_width // 2\n",
        "    y_dest -= bastards_into_canvas_height // 2\n",
        "\n",
        "    # if idx < 20:\n",
        "    #  print(f'x: {x}, y: {y}, x_dest: {x_dest}, y_dest: {y_dest}')\n",
        "    return (x_dest, y_dest)\n",
        "\n",
        "  idx = 0\n",
        "  # TODO: nasty, shouldn't be reading file again. weak\n",
        "  for file in files:\n",
        "    a_bastard = Image.open(os.path.join(\"allbastards.com/public/img/full\",file))\n",
        "    if not a_bastard.is_animated:\n",
        "      a_smaller_bastard = a_bastard.resize(bastards_into_canvas_size)\n",
        "      location = translate_to_canvas(embedding[idx,0], embedding[idx,1])\n",
        "      # if idx < 20:\n",
        "      #   print(location)\n",
        "      canvas.paste(a_smaller_bastard, location) #, mask=a_smaller_bastard)\n",
        "      idx = idx + 1\n",
        "\n",
        "  print(f'number of files plotted: {idx}')\n",
        "  return canvas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyNe8kLVOIDE"
      },
      "outputs": [],
      "source": [
        "# TODO: implement progress bars for slow cells\n",
        "\n",
        "# from ipywidgets import IntProgress\n",
        "# from IPython.display import display\n",
        "# import time\n",
        "\n",
        "#max_count = 100\n",
        "\n",
        "#progress_bar = IntProgress(min=0, max=max_count) # instantiate the bar\n",
        "#display(progress_bar) # display the bar\n",
        "\n",
        "#count = 0\n",
        "#while count <= max_count:\n",
        "#    progress_bar.value += 1 # signal to increment the progress bar\n",
        "#    # time.sleep(.1)\n",
        "#    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jxZYyIznTpZ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# This has been seen to take:\n",
        "# NFTs plotted at \n",
        "# -   (64, 64): ~2.0m -- ~2.5m\n",
        "# - (128, 128): ~2.5m\n",
        "\n",
        "if render_2d_plots:\n",
        "  print(f'start scattering at {datetime.datetime.now()}')\n",
        "  scattered_bastards = scatter_bastards_in_2d(invert_vertically = False)\n",
        "  print(f'done scattering at {datetime.datetime.now()}')\n",
        "  display(scattered_bastards)\n",
        "  print(f'done displaying at {datetime.datetime.now()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcf1UsAR21F-"
      },
      "source": [
        "#### 3D hypermap the calmAFs\n",
        "\n",
        "Next, feed the data into TensorBoard's Embedding Projector (or simply, Projector). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXYhzjK04BIu"
      },
      "source": [
        "##### Sprite sheet\n",
        "\n",
        "To actually show the images floating in a 2D or 3D space, TensorBoard Projector requires a sprite sheet which contains a sprite for each image to be projected.\n",
        "\n",
        "For now we're just using the calmAFs (static images), not the hypedAFs (animated GIFs). There are 10459 calms and 847 hypeds. The sprite sheet needs to be square, so let's just use the first 10000, for 100 x 100 sprite sheet. [TODO: plot all 10459 calms.]\n",
        "\n",
        "The sprite sheet can be a PNG or a JPEG. (Not sure if an animated GIF will work in Projector.) So, for just-the-calms we'll go PNG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Xe5Izz37qO"
      },
      "outputs": [],
      "source": [
        "def create_sprite_sheet():\n",
        "  spritesheet_square_length = 100 # 10,000 = 100 x 100 in spritesheet\n",
        "  master_width = bastards_into_projector_witdth * spritesheet_square_length\n",
        "  master_height = bastards_into_projector_witdth * spritesheet_square_length\n",
        "  spriteimage = Image.new(\n",
        "    mode='RGBA',\n",
        "    size=(master_width, master_height),\n",
        "    color=(0,0,0,0) # fully transparent\n",
        "  )\n",
        "\n",
        "  # This CUT_OFF_LIMIT is a vile hack. Spritesheet must be square. Padding needed, but not now\n",
        "  CUT_OFF_LIMIT = 10000 # TODO: remove this hack, sprite up ENTIRE collection\n",
        "\n",
        "  punk_index = 0\n",
        "  for x in range(CUT_OFF_LIMIT):\n",
        "    a_punk = get_bastard_by_id(calm_ids[x]).resize(bastards_into_projector_size)\n",
        "    div, mod = divmod(punk_index, spritesheet_square_length)\n",
        "    h_loc = bastards_into_projector_witdth * div\n",
        "    w_loc = bastards_into_projector_witdth * mod\n",
        "    spriteimage.paste(a_punk, (w_loc, h_loc))\n",
        "    punk_index = punk_index + 1\n",
        "\n",
        "  return spriteimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP6DK-lK6BS6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# This cell has been seen to take ~2min for (128, 128)\n",
        "\n",
        "def write_files_for_tensorboard():\n",
        "  # First, generate spritesheet for Projector to use downsammpled sprites\n",
        "  sprite_sheet = create_sprite_sheet()\n",
        "  sprite_filename = os.path.join(tensorboard_data_dump_dir, 'embeddings/sprite.png')\n",
        "  if not os.path.exists(os.path.dirname(sprite_filename)):\n",
        "    os.makedirs(os.path.dirname(sprite_filename))\n",
        "  sprite_sheet.save(sprite_filename)\n",
        "\n",
        "  # Next the data for the dimensionality reducers (UMAP, t-SNE, PCA) to crunch on\n",
        "  vectorized_punks = tf.Variable(calms[0:9999])\n",
        "  checkpoint = tf.train.Checkpoint(embedding=vectorized_punks)\n",
        "  checkpoint.save(os.path.join(tensorboard_data_dump_dir, 'embedding.ckpt'))\n",
        "\n",
        "\n",
        "  config = projector.ProjectorConfig()\n",
        "  embedder = config.embeddings.add()\n",
        "\n",
        "  embedder.tensor_name = 'embedding/.ATTRIBUTES/VARIABLE_VALUE'\n",
        "\n",
        "  embedder.sprite.image_path = sprite_filename\n",
        "  embedder.sprite.single_image_dim.extend(bastards_into_projector_size)\n",
        "\n",
        "  projector.visualize_embeddings(tensorboard_data_dump_dir, config)\n",
        "\n",
        "write_files_for_tensorboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGVhvRrSFp2s"
      },
      "source": [
        "##### Projector \n",
        "\n",
        "**Bug in TensorBoard launch**\n",
        "\n",
        "**NOTE:** TensorBoard regularly fails to find the data just written to the file system. If so just rerun the following cell; that usually gets it to wake up and get to work.\n",
        "\n",
        "Also note that:\n",
        "- \"Fetching tensor values…\" normally takes a minute or two\n",
        "- \"Fetching sprite image…\" normally takes a minute\n",
        "- Then PCA will run automatically\n",
        "- When PCA is done, click on UMAP or tSNE for other hypermap algorithms that will each provide a different view of the collection.\n",
        "\n",
        "☝ ↑ ☝ ↑ ☝ ↑ ☝ ↑ ☝ ↑ ☝ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqtKUjsm2eSu"
      },
      "outputs": [],
      "source": [
        "# If this results in \"No datasets found\" then simply rerun this cell\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir={tensorboard_data_dump_dir}\n",
        "\n",
        "# If this results in \"No datasets found\" then simply rerun this cell\n",
        "\n",
        "# TODO: errors seen that need to be worked out\n",
        "# - \"Error parsing tensor bytes\" \n",
        "# - \"Error parsing tensor bytes RangeError: byte length of Float32Array should be a multiple of 4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIPQMK0eHUi"
      },
      "source": [
        "## History\n",
        "\n",
        "- v1.1.1 (2022-01-30, John Tigue):\n",
        "  - Cleaned up and made public for first time\n",
        "- v1.1.0 (2022-01-29, John Tigue):\n",
        "  - 2D canvas of any size via constants\n",
        "  - 2D canvas gets backround gradient\n",
        "  - 2D canvas padding as constant\n",
        "- v1.0.3 (2022-01-21, John Tigue):\n",
        "  - UMAP to 2D at (128,128) on (4096, 4096) for Twitter\n",
        "  - Add gradient background\n",
        "  - Add labeling\n",
        "- v1.0.2 (2022-01-20, John Tigue): \n",
        "  - UMAP'ed at (48px, 48px)\n",
        "  - Projected at (64px, 64px) \n",
        "- v1.0.1 (2022-01-11, John Tigue): \n",
        "  - Added Intro text\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PKQJnrVyhmDl",
        "BpA8XJwViMAP",
        "AwuRaZsOHoG7",
        "3AQR010U82wo",
        "MwQGjhOu7dEe",
        "YzwKUbeS75c8",
        "OlIPQMK0eHUi"
      ],
      "name": "hypermap_bganpunks.ipynb",
      "provenance": []
    },
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}